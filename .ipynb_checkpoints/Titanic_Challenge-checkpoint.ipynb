{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1aa1fea-c7d6-4236-9299-ec8ffea173d4",
   "metadata": {},
   "source": [
    "## Titanic Challeneg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "175b2626-4746-4f05-a201-5ce72a07dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bb24e4d9-9038-4115-bf26-6dfd7b060ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyReport(clf,X,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Train Score --------------------------------**********\")\n",
    "    print(\"Accuracy score is \",accuracy_score(y_train,clf.predict(X_train)))\n",
    "    print(classification_report(y_train,clf.predict(X_train)))\n",
    "    print(confusion_matrix(y_train,clf.predict(X_train)))\n",
    "    print(\"Test Score --------------------------------**********\")\n",
    "    print(\"Accuracy score is \",accuracy_score(y_test,clf.predict(X_test)))\n",
    "    print(classification_report(y_test,clf.predict(X_test)))\n",
    "    print(confusion_matrix(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "95e2b4a4-c662-47fe-ae18-55ddcf264c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(df):\n",
    "    sex_to_num = {\n",
    "    'male':1,\n",
    "    'female':2\n",
    "    }\n",
    "    embarked_to_num = {\n",
    "    'C':0,\n",
    "    'Q':1,\n",
    "    'S':2\n",
    "    }\n",
    "    df = df.drop(['Name','Ticket','Cabin'],axis=1)\n",
    "    df['sex_to_num'] = df['Sex'].map(sex_to_num) \n",
    "    df = df.drop('Sex',axis=1)\n",
    "    df['embarked_to_num'] = df['Embarked'].map(embarked_to_num) \n",
    "    df = df.drop('Embarked',axis=1)\n",
    "    df['Age'] = df['Age'].fillna(29.6)\n",
    "    df['embarked_to_num'] = df['embarked_to_num'].fillna(2)\n",
    "    df['Fare'] = df['embarked_to_num'].fillna(32.204208)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "213ddc66-c96e-4c2c-a1fc-b6ae2b302339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>sex_to_num</th>\n",
       "      <th>embarked_to_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.679428</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>1.536476</td>\n",
       "      <td>1.352413</td>\n",
       "      <td>1.536476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002075</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.791503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.679428    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.002075    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   29.600000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  sex_to_num  embarked_to_num  \n",
       "count  891.000000  891.000000  891.000000       891.000000  \n",
       "mean     0.381594    1.536476    1.352413         1.536476  \n",
       "std      0.806057    0.791503    0.477990         0.791503  \n",
       "min      0.000000    0.000000    1.000000         0.000000  \n",
       "25%      0.000000    1.000000    1.000000         1.000000  \n",
       "50%      0.000000    2.000000    1.000000         2.000000  \n",
       "75%      0.000000    2.000000    2.000000         2.000000  \n",
       "max      6.000000    2.000000    2.000000         2.000000  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = preProcess(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b5f4403b-583e-4cb2-9ad9-5e9363e035a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['Pclass','Age','SibSp','Parch','Fare','sex_to_num','embarked_to_num']\n",
    "\n",
    "null_cols = df.isnull().any()\n",
    "\n",
    "# print the column names with null values\n",
    "print(null_cols[null_cols == True].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4e5e4217-6f65-4dab-bbc0-8fd239e3bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_cols]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9642e269-ae82-43a3-9582-9d73aaa150b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score --------------------------------**********\n",
      "Accuracy score is  0.9400749063670412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       326\n",
      "           1       0.97      0.87      0.92       208\n",
      "\n",
      "    accuracy                           0.94       534\n",
      "   macro avg       0.95      0.93      0.94       534\n",
      "weighted avg       0.94      0.94      0.94       534\n",
      "\n",
      "[[321   5]\n",
      " [ 27 181]]\n",
      "Test Score --------------------------------**********\n",
      "Accuracy score is  0.7983193277310925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       223\n",
      "           1       0.72      0.75      0.74       134\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.78      0.79      0.79       357\n",
      "weighted avg       0.80      0.80      0.80       357\n",
      "\n",
      "[[185  38]\n",
      " [ 34 100]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = DecisionTreeClassifier(random_state = 42)\n",
    "accuracyReport(clf,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "344af5ae-1aec-4ecc-9611-d0a72aac9371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score --------------------------------**********\n",
      "Accuracy score is  0.9456928838951311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       319\n",
      "           1       0.96      0.90      0.93       215\n",
      "\n",
      "    accuracy                           0.95       534\n",
      "   macro avg       0.95      0.94      0.94       534\n",
      "weighted avg       0.95      0.95      0.95       534\n",
      "\n",
      "[[311   8]\n",
      " [ 21 194]]\n",
      "Test Score --------------------------------**********\n",
      "Accuracy score is  0.7899159663865546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83       230\n",
      "           1       0.69      0.74      0.71       127\n",
      "\n",
      "    accuracy                           0.79       357\n",
      "   macro avg       0.77      0.78      0.77       357\n",
      "weighted avg       0.79      0.79      0.79       357\n",
      "\n",
      "[[188  42]\n",
      " [ 33  94]]\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(estimator=clf, n_estimators=1000,\n",
    "                            bootstrap=True, oob_score=True,\n",
    "                            n_jobs=-1, random_state=42)\n",
    "accuracyReport(bag_clf,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "572a0dd9-09b6-4b9e-9a00-f4dc00325218",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[1;32m      4\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m,)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m      ]\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(    loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(),\n\u001b[1;32m     10\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m),)\n\u001b[0;32m---> 11\u001b[0m \u001b[43maccuracyReport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[258], line 3\u001b[0m, in \u001b[0;36maccuracyReport\u001b[0;34m(clf, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccuracyReport\u001b[39m(clf,X,y):\n\u001b[1;32m      2\u001b[0m     X_train,X_test,y_train,y_test \u001b[38;5;241m=\u001b[39m train_test_split(X,y,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Score --------------------------------**********\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy score is \u001b[39m\u001b[38;5;124m\"\u001b[39m,accuracy_score(y_train,clf\u001b[38;5;241m.\u001b[39mpredict(X_train)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/xk/_k12j4y15611c3blv38bx6xh0000gn/T/__autograph_generated_filei62uf1_q.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Users/supreethavadhani/opt/anaconda3/envs/ML_python_training/lib/python3.9/site-packages/keras/backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(7,)),\n",
    "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
    "        Dense(1, activation='sigmoid', name = 'layer2')\n",
    "     ]\n",
    ")\n",
    "model.compile(    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),)\n",
    "accuracyReport(model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d7c33-a556-482e-81ff-8e2480b588d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c9c8541c-68d3-4a9d-8602-6ee825c0ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('test.csv')\n",
    "final_df = preProcess(final_df)\n",
    "final_df.describe()\n",
    "X = final_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2dca585f-3c58-4638-92e8-6f6f7873bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()\n",
    "predict_vals = bag_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "90a55629-6aed-45b8-bd22-a6a582cec6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"PassengerId\": [],\n",
    "    \"Survived\": []\n",
    "}\n",
    "for i in range(892, 1310):\n",
    "    data[\"PassengerId\"].append(i)\n",
    "    data[\"Survived\"].append(None)\n",
    "df = pd.DataFrame(data)\n",
    "df_1 = pd.DataFrame(predict_vals)\n",
    "df['Survived'] = df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b82e4d8c-032c-41d9-ad8c-1bc9959e4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result_data_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "990aecbc-9144-4d4d-a0ef-68c05a83631f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fa3e3325-d605-475a-b51d-4fcf1a9de23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:50:27.050723: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55815a29-8ddd-4918-baac-98923ab38847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
